import asyncio
import json
import logging
import signal
import sys
import traceback
import uuid
from typing import Any, Dict, Optional, Callable, Awaitable
import aio_pika
from aio_pika import Message, DeliveryMode, ExchangeType
from aio_pika.abc import AbstractIncomingMessage
from aio_pika.exceptions import MessageProcessError

from src.core import logger
from src.core.db.db_database import AsyncDatabaseTool
from src.core.db.db_redis import AsyncRedisTool
from src.core.log.logger import init_logger
from src.utils.track_utils import TrackContextUtils



class AsyncConsumer:
    """
    å¼‚æ­¥æ¶ˆæ¯æ¶ˆè´¹è€…åŸºç±»

    æä¾›å®Œæ•´çš„æ¶ˆæ¯é˜Ÿåˆ—æ¶ˆè´¹åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - è¿æ¥ç®¡ç†
    - å¹¶å‘æ§åˆ¶
    - é‡è¯•ç­–ç•¥
    - æ­»ä¿¡é˜Ÿåˆ—
    - ä¼˜é›…å…³é—­
    - å¥åº·æ£€æŸ¥
    """

    def __init__(
            self,
            amqp_url: str,
            queue_name: str,
            exchange_name: Optional[str] = None,
            exchange_type: str = "direct",
            routing_key: Optional[str] = None,
            require_ack: bool = True,
            max_priority: Optional[int] = None,
            max_interval_retries: int = 0,
            retry_interval: int = 1,
            max_requeue_retries: int = 0,
            dlx_exchange: Optional[str] = None,
            dlx_queue: Optional[str] = None,
            prefetch_count: int = 1,
    ):
        # éªŒè¯é…ç½®
        self._validate_config(
            prefetch_count, exchange_type, max_interval_retries,
            retry_interval, max_requeue_retries
        )

        # åŸºç¡€é…ç½®
        self.amqp_url = amqp_url
        self.queue_name = queue_name
        self.exchange_name = exchange_name
        self.exchange_type = exchange_type
        self.routing_key = routing_key
        self.require_ack = require_ack
        self.max_priority = max_priority

        # é‡è¯•é…ç½®
        # self.max_interval_retries = max_interval_retries
        self.retry_interval = retry_interval
        self.max_requeue_retries = max_requeue_retries

        # æ­»ä¿¡é˜Ÿåˆ—é…ç½®
        self.dlx_exchange_name = dlx_exchange
        self.dlx_queue_name = dlx_queue

        # å¹¶å‘æ§åˆ¶
        self.prefetch_count = prefetch_count
        self._processing_semaphore = asyncio.Semaphore(prefetch_count)

        # MQ è¿æ¥èµ„æº
        self.connection: Optional[aio_pika.Connection] = None
        self.channel: Optional[aio_pika.Channel] = None
        self.exchange: Optional[aio_pika.Exchange] = None
        self.queue: Optional[aio_pika.Queue] = None
        self.dlx_exchange: Optional[aio_pika.Exchange] = None
        self.dlx_queue: Optional[aio_pika.Queue] = None

        # ä¸­é—´ä»¶èµ„æº
        self.async_db = AsyncDatabaseTool()
        self.async_redis = AsyncRedisTool(start_health_check=False)

        # ç”Ÿå‘½å‘¨æœŸå›è°ƒ
        self.release_callback: Optional[Callable[[], Awaitable[None]]] = None

        # è¿è¡ŒçŠ¶æ€
        self._running = False
        self._shutdown_event = asyncio.Event()

        self._stop_consuming = False  # åœæ­¢æ¶ˆè´¹æ–°æ¶ˆæ¯
        self._active_messages = 0  # å½“å‰å¤„ç†ä¸­çš„æ¶ˆæ¯æ•°

    def _validate_config(
            self,
            prefetch_count: int,
            exchange_type: str,
            max_interval_retries: int,
            retry_interval: int,
            max_requeue_retries: int
    ) -> None:
        """éªŒè¯é…ç½®å‚æ•°"""
        if prefetch_count <= 0:
            raise ValueError("prefetch_count must be positive")
        if exchange_type not in ["direct", "topic", "headers", "fanout"]:
            raise ValueError(f"Invalid exchange_type: {exchange_type}")
        # if max_interval_retries < 0:
        #     raise ValueError("max_interval_retries must be non-negative")
        if retry_interval <= 0:
            raise ValueError("retry_interval must be positive")
        if max_requeue_retries < 0:
            raise ValueError("max_requeue_retries must be non-negative")

    # ==================== ç”Ÿå‘½å‘¨æœŸç®¡ç† ====================

    async def _init_middleware(self) -> None:
        """åˆå§‹åŒ–ä¸­é—´ä»¶èµ„æº"""
        try:
            # ç¡®ä¿æ•°æ®åº“è¿æ¥æ­£å¸¸
            # await self._ensure_database_connection()
            self.async_redis.start_health_check()
            init_logger(intercept_std_logging=True, level=logging.INFO)
        except Exception as e:
            logger.error(f"Failed to initialize middleware: {e}")
            raise


    async def _close_middleware(self) -> None:
        """å…³é—­ä¸­é—´ä»¶èµ„æº"""
        errors = []

        # é€ä¸ªå…³é—­ï¼Œç¡®ä¿æ¯ä¸ªèµ„æºéƒ½èƒ½å°è¯•å…³é—­
        try:
            await self.async_db.close_pool()
        except Exception as e:
            errors.append(f"DB close error: {e}")
            logger.error(f"Error closing database pool: {e}")

        try:
            await self.async_redis.close_pool()
        except Exception as e:
            errors.append(f"Redis close error: {e}")
            logger.error(f"Error closing redis pool: {e}")

        if errors:
            raise Exception(f"Multiple close errors: {', '.join(errors)}")

    async def _connect_mq(self) -> None:
        """å»ºç«‹MQè¿æ¥å’Œå£°æ˜é˜Ÿåˆ—"""
        try:
            # åˆ›å»ºè¿æ¥å’Œé€šé“
            self.connection = await aio_pika.connect_robust(self.amqp_url)
            self.channel = await self.connection.channel()

            # è®¾ç½®QoS
            await self.channel.set_qos(prefetch_count=self.prefetch_count)

            # å£°æ˜æ­»ä¿¡é˜Ÿåˆ—ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            await self._declare_dead_letter_queue()

            # å£°æ˜ä¸»é˜Ÿåˆ—å’Œäº¤æ¢æœº
            await self._declare_main_queue()

            # åˆå§‹åŒ–ä¸­é—´ä»¶
            await self._init_middleware()

            logger.info(f"MQ connection established for queue: {self.queue_name}")

        except Exception as e:
            logger.error(f"Failed to connect to MQ: {e}")
            await self._close_mq()
            raise

    async def _declare_dead_letter_queue(self) -> None:
        """å£°æ˜æ­»ä¿¡é˜Ÿåˆ—"""
        if not (self.dlx_exchange_name and self.dlx_queue_name):
            return

        try:
            self.dlx_exchange = await self.channel.declare_exchange(
                self.dlx_exchange_name, ExchangeType.DIRECT, durable=True
            )

            self.dlx_queue = await self.channel.declare_queue(
                self.dlx_queue_name,
                durable=True,
                arguments={"x-dead-letter-exchange": self.dlx_exchange.name}
            )

            await self.dlx_queue.bind(self.dlx_exchange, routing_key=self.routing_key)
            logger.info(f"Dead letter queue declared: {self.dlx_queue_name}")

        except Exception as e:
            logger.error(f"Failed to declare dead letter queue: {e}")
            raise

    async def _declare_main_queue(self) -> None:
        """å£°æ˜ä¸»é˜Ÿåˆ—å’Œäº¤æ¢æœº"""
        # æ„å»ºé˜Ÿåˆ—å‚æ•°
        arguments = {}
        if self.max_priority:
            arguments["x-max-priority"] = self.max_priority
        if self.dlx_exchange:
            arguments["x-dead-letter-exchange"] = self.dlx_exchange.name

        # å£°æ˜é˜Ÿåˆ—
        self.queue = await self.channel.declare_queue(
            self.queue_name, durable=True, arguments=arguments
        )

        # å£°æ˜å’Œç»‘å®šäº¤æ¢æœº
        if self.exchange_name:
            self.exchange = await self.channel.declare_exchange(
                self.exchange_name, ExchangeType(self.exchange_type), durable=True
            )
            await self.queue.bind(self.exchange, routing_key=self.routing_key)


    async def _close_mq(self) -> None:
        """å…³é—­MQè¿æ¥"""
        # åˆ†åˆ«å…³é—­ï¼Œé¿å…ä¸€ä¸ªå¤±è´¥å½±å“å…¶ä»–
        if self.channel:
            try:
                await asyncio.wait_for(self.channel.close(), timeout=5.0)
            except asyncio.TimeoutError:
                logger.warning("Channel close timeout")
            except asyncio.CancelledError:
                logger.info("Channel close cancelled")
            except Exception as e:
                logger.error(f"Error closing channel: {e}")

        if self.connection:
            try:
                await asyncio.wait_for(self.connection.close(), timeout=5.0)
            except asyncio.TimeoutError:
                logger.warning("ğŸ‘‹ Connection close timeout ğŸ‘‹")
            except asyncio.CancelledError:
                logger.info("ğŸ‘‹ Connection close cancelled ğŸ‘‹")
            except Exception as e:
                logger.error(f"Error closing connection: {e}")

    # ==================== æ¶ˆæ¯å¤„ç† ====================

    async def _on_message(self, message: AbstractIncomingMessage) -> None:
        """æ¶ˆæ¯å¤„ç†å…¥å£"""

        # å¦‚æœæ­£åœ¨å…³é—­ï¼Œæ‹’ç»æ–°æ¶ˆæ¯
        if self._stop_consuming and self.channel and not self.channel.is_closed:
            # logger.info("Rejecting new message due to shutdown")
            if self.require_ack:
                await message.nack(requeue=True)  # é‡æ–°æ’é˜Ÿ
            return

        async with self._processing_semaphore:
            try:
                self._active_messages += 1
                await self._process_message_safe(message)
            except Exception as e:
                logger.error(f"Unexpected error in message processing: {e}")
                if self.require_ack:
                    await message.nack(requeue=False)
            finally:
                self._active_messages -= 1

    async def _process_message_safe(self, message: AbstractIncomingMessage) -> None:
        """å®‰å…¨çš„æ¶ˆæ¯å¤„ç†æµç¨‹"""
        try:
            # è®¾ç½®ä¸Šä¸‹æ–‡
            TrackContextUtils.set_request_id(title="consumer")

            # è§£ææ¶ˆæ¯ä½“
            body = await self._parse_message_body(message.body)

            logger.info(f"Received message: {body}")

            # æ‰§è¡Œå¤„ç†é€»è¾‘ï¼ˆå¸¦é‡è¯•ï¼‰
            result_info  = await self.handle_message(body)

            # å¤„ç†ACK/NACK
            await self._handle_ack_nack(message, result_info)

        except json.JSONDecodeError:
            logger.error(f" Invalid JSON message: {message.body.decode('utf-8', errors='replace')}")
            if self.require_ack:
                await message.nack(requeue=False)

        except Exception as e:
            logger.error(f" Processing error: {e}\n{traceback.format_exc()}")
            if self.require_ack:
                await message.nack(requeue=False)

    async def _parse_message_body(self, body_bytes: bytes) -> Dict[str, Any]:
        """å¼‚æ­¥è§£ææ¶ˆæ¯ä½“"""
        # å°æ¶ˆæ¯ä½“ç›´æ¥è§£æï¼Œå¤§æ¶ˆæ¯ä½“ä½¿ç”¨çº¿ç¨‹æ± 
        if len(body_bytes) < 1024:  # 1KBé˜ˆå€¼
            return json.loads(body_bytes)
        else:
            loop = asyncio.get_running_loop()
            return await loop.run_in_executor(None, json.loads, body_bytes)

    # async def _execute_with_retry(self, body: Dict[str, Any]) -> bool:
    #     """æ‰§è¡Œå¸¦é‡è¯•çš„å¤„ç†é€»è¾‘"""
    #     retry_count = 0
    #
    #     while retry_count <= self.max_interval_retries:
    #         try:
    #             if retry_count > 0:
    #                 logger.info(f" Retrying (attempt {retry_count})")
    #                 await asyncio.sleep(self.retry_interval)
    #
    #             success = await self.handle_message(body)
    #
    #             # å¤„ç†æˆåŠŸæˆ–æ˜ç¡®æˆåŠŸ
    #             if success in [True, None]:
    #                 logger.info(f" Processing successful")
    #                 return True
    #
    #             # å¤„ç†å¤±è´¥ï¼Œç»§ç»­é‡è¯•
    #             retry_count += 1
    #             logger.warning(f" Processing failed, retrying...")
    #
    #         except Exception as e:
    #             logger.error(f" Exception in handle_message: {e}")
    #             retry_count += 1
    #
    #     # é‡è¯•è€—å°½
    #     logger.error(f" Max retries ({self.max_interval_retries}) exceeded")
    #     return False

    async def _handle_ack_nack(self, message: AbstractIncomingMessage, result_info: dict) -> None:
        """å¤„ç†æ¶ˆæ¯ç¡®è®¤"""
        if not self.require_ack:
            return

        if result_info.get("basic_ack"):
            await message.ack()
            logger.info(f" Message acknowledged")
            return

        # å¤„ç†å¤±è´¥çš„æƒ…å†µ
        await self._handle_failed_message(message, result_info)

    async def _handle_failed_message(self, message: AbstractIncomingMessage, result_info) -> None:
        """å¤„ç†å¤±è´¥æ¶ˆæ¯çš„é‡è¯•æˆ–æ­»ä¿¡"""
        if not self.max_requeue_retries:
            # æ²¡æœ‰é…ç½®é‡è¯•ï¼Œç›´æ¥å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
            # requeue = False if self.dlx_queue else True
            requeue = result_info.get("requeue")
            await message.nack(requeue=requeue)
            logger.info(f" Message nacked (requeue={requeue})")
            return

        # æ‰§è¡Œé‡è¯•é€»è¾‘
        await self._handle_requeue_retry(message)

    async def _handle_requeue_retry(self, message: AbstractIncomingMessage) -> None:
        """å¤„ç†é‡æ–°å…¥é˜Ÿé‡è¯•"""
        try:
            headers = message.headers or {}
            current_retry_count = headers.get("x-retry-count", 0)

            # ä½¿ç”¨åŸå­æ“ä½œæ›´æ–°è®¡æ•°
            new_retry_count = current_retry_count + 1
            updated_headers = dict(headers)  # åˆ›å»ºå‰¯æœ¬é¿å…ç«æ€
            updated_headers["x-retry-count"] = new_retry_count

            if new_retry_count <= self.max_requeue_retries:
                # é‡æ–°å‘å¸ƒæ¶ˆæ¯
                await self.channel.default_exchange.publish(
                    Message(
                        body=message.body,
                        delivery_mode=DeliveryMode.PERSISTENT,
                        headers=updated_headers,
                        content_type=message.content_type,
                        content_encoding=message.content_encoding,
                        correlation_id=message.correlation_id,
                        expiration=message.expiration,
                        message_id=message.message_id,
                        user_id=message.user_id,
                        app_id=message.app_id,
                        type=message.type,
                    ),
                    routing_key=self.routing_key,
                )

                await message.ack()
                logger.info(f" Message requeued (retry {new_retry_count})")

            else:
                # é‡è¯•æ¬¡æ•°è€—å°½
                logger.warning(f" Requeue retries exhausted")
                requeue = False if self.dlx_queue else True
                await message.nack(requeue=requeue)
                logger.info(f" Message nacked (requeue={requeue})")

        except Exception as e:
            logger.error(f" Error in requeue retry: {e}")
            await message.nack(requeue=False)


    # ==================== å…¬å…±æ¥å£ ====================

    async def handle_message(self, body: Dict[str, Any]) -> bool:
        """
        å¤„ç†æ¶ˆæ¯çš„æ ¸å¿ƒé€»è¾‘

        Args:
            body: è§£æåçš„æ¶ˆæ¯ä½“

        Returns:
            bool: True/None è¡¨ç¤ºæˆåŠŸï¼ŒFalse è¡¨ç¤ºå¤±è´¥
        """
        raise NotImplementedError("Subclasses must implement handle_message")

    async def start_consuming(self) -> None:
        """å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯"""
        await self.queue.consume(self._on_message, no_ack=not self.require_ack)
        logger.info(f"Started consuming from queue: {self.queue_name}")

    async def run(self) -> None:
        """è¿è¡Œæ¶ˆè´¹è€…"""
        await self._connect_mq()
        await self.start_consuming()

        # ç­‰å¾…å…³é—­ä¿¡å·
        await self._shutdown_event.wait()

    async def close(self) -> None:
        """å…³é—­æ¶ˆè´¹è€…"""
        logger.info("Closing consumer...")
        await self._close_mq()
        await self._close_middleware()
        logger.info("Consumer closed")

    def start(self) -> None:
        """å¯åŠ¨æ¶ˆè´¹è€…ï¼ˆé˜»å¡æ¨¡å¼ï¼‰"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            # è®¾ç½®ä¿¡å·å¤„ç†å™¨
            self._setup_signal_handlers(loop)

            logger.info(
                f"Starting consumer - exchange: {self.exchange_name}, "
                f"queue: {self.queue_name}, routing_key: {self.routing_key}"
            )

            # å¯åŠ¨æ¶ˆè´¹ä»»åŠ¡
            loop.create_task(self.run())
            loop.run_forever()

        except (KeyboardInterrupt, SystemExit):
            logger.info("Shutdown signal received")
        finally:
            loop.run_until_complete(self.close())
            loop.close()
            logger.info("Shutdown complete")

    def _setup_signal_handlers(self, loop: asyncio.AbstractEventLoop) -> None:
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""

        def shutdown_handler():
            logger.info("Shutdown handler triggered")
            logger.info(f"Shutdown: waiting for {self._active_messages} active messages")
            self._stop_consuming = True
            # å¦‚æœæ²¡æœ‰æ´»åŠ¨æ¶ˆæ¯ï¼Œç›´æ¥é€€å‡º
            def check_and_shutdown():
                """æ£€æŸ¥æ˜¯å¦å¯ä»¥å…³é—­ï¼Œå¦‚æœä¸è¡Œåˆ™ç»§ç»­ç­‰å¾…"""
                if self._active_messages == 0:
                    # æ²¡æœ‰æ´»åŠ¨æ¶ˆæ¯ï¼Œç«‹å³é€€å‡º
                    logger.info("No active messages, shutting down immediately")
                    self._shutdown_event.set()
                    loop.call_soon(loop.stop)  # âœ… ç«‹å³åœæ­¢å¾ªç¯
                else:
                    # è¿˜æœ‰æ´»åŠ¨æ¶ˆæ¯ï¼Œç»§ç»­ç­‰å¾…
                    logger.debug(f"Still waiting for {self._active_messages} messages...")
                    # 1 ç§’åå†æ¬¡æ£€æŸ¥
                    loop.call_later(1, check_and_shutdown)

            def force_shutdown():
                """30ç§’è¶…æ—¶å¼ºåˆ¶å…³é—­"""
                remaining = self._active_messages
                if remaining > 0:
                    logger.warning(f"Force shutdown: {remaining} messages still active")
                    # å¼ºåˆ¶å–æ¶ˆä»»åŠ¡
                    try:
                        tasks = [
                            t for t in asyncio.all_tasks(loop)
                            if t is not asyncio.current_task(loop) and not t.done()
                        ]
                        for task in tasks:
                            task.cancel()
                    except Exception as e:
                        logger.error(f"Error cancelling tasks: {e}")
                else:
                    logger.info("All messages completed, shutting down gracefully")

                self._shutdown_event.set()
                loop.call_soon(loop.stop)

            # å¼€å§‹æ£€æŸ¥
            loop.call_soon(check_and_shutdown)
            # è®¾ç½®30ç§’è¶…æ—¶
            loop.call_later(30.0, force_shutdown)

        if sys.platform != "win32":
            for signame in {"SIGINT", "SIGTERM"}:
                try:
                    loop.add_signal_handler(getattr(signal, signame), shutdown_handler)
                except ValueError as e:
                    logger.warning(f"Failed to set signal handler for {signame}: {e}")
